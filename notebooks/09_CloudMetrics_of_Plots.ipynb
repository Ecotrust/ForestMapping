{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will execute a series of commands to calculate summary metrics about the point clouds on forest inventory plots.\n",
    "\n",
    "We will:\n",
    "1. Classify ground vs. non-ground points for the hectare-sized plot\n",
    "2. Clip the hectare-sized classified plot to the appropriate plot size\n",
    "3. Generate a hectare-sized plot with points normalized as height above ground\n",
    "4. Generate a canopy height model from the normalized hectare-sized plot.\n",
    "5. Calculate GridSurfaceStats for each hectare-sized plot\n",
    "6. Calculate TopoMetrics for each hectare-sized plot\n",
    "7. Extract GridSurfaceStats for each appropriately-sized plot using zonal statistics\n",
    "8. Extract TopoMetrics for each appropriately-sized plot using zonal statistics\n",
    "9. Clip the normalized hectare plot point cloud to appropriate plot size\n",
    "10. Execute CloudMetrics for the normalized plot-sized clip\n",
    "11. Consolidate CloudMetrics and TopoMetrics outputs into a single text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "import dask\n",
    "from dask.distributed import progress, Client, LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster=LocalCluster(scheduler_port=7001, diagnostics_port=7002)\n",
    "c = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOTS = '../data/processed/blm_usfs_wadnr_plots_1ha.shp'\n",
    "plots = gpd.read_file(PLOTS)\n",
    "plots['geometry'] = plots.centroid\n",
    "\n",
    "UTM_10 = '../data/external/utm_zone10_epsg4326.shp'\n",
    "UTM_11 = '../data/external/utm_zone11_epsg4326.shp'\n",
    "utm_10 = gpd.read_file(UTM_10)\n",
    "utm_11 = gpd.read_file(UTM_11)\n",
    "utm_zones = pd.concat((utm_10, utm_11),\n",
    "                      axis=0,\n",
    "                      ignore_index=True)[['geometry', 'ZONE']]\n",
    "\n",
    "plot_utm = gpd.sjoin(plots, utm_zones)[['uuid', 'ZONE', 'source', 'geometry']].set_index('uuid')\n",
    "plot_utm['epsg'] = plot_utm.ZONE.apply(lambda x: 6339 if (x == '10') else 6340)\n",
    "\n",
    "# define the utm coordinates of the centroid of each plot in that zone\n",
    "for epsg in [6339, 6340]:\n",
    "    plot_utm.loc[plot_utm.epsg == epsg, 'utm_x'] = plot_utm.loc[plot_utm.epsg == epsg].to_crs({'init': 'epsg:{}'.format(epsg)}).centroid.x\n",
    "    plot_utm.loc[plot_utm.epsg == epsg, 'utm_y'] = plot_utm.loc[plot_utm.epsg == epsg].to_crs({'init': 'epsg:{}'.format(epsg)}).centroid.y\n",
    "\n",
    "plot_utm = plot_utm[['source', 'utm_x', 'utm_y', 'ZONE']]\n",
    "\n",
    "def get_utm_location(infile, is_uuid=False):\n",
    "    if is_uuid:\n",
    "        uuid = infile\n",
    "    else:\n",
    "        basename = os.path.basename(infile)\n",
    "        uuid = basename.split('_')[0]\n",
    "    utm_x, utm_y, utm_zone = plot_utm.loc[uuid][['utm_x', 'utm_y', 'ZONE']]\n",
    "    return utm_x, utm_y, utm_zone + 'N'\n",
    "\n",
    "def get_latitude(infile, is_uuid=False):\n",
    "    if is_uuid:\n",
    "        uuid = infile\n",
    "    else:\n",
    "        basename = os.path.basename(infile)\n",
    "        uuid = basename.split('_')[0]\n",
    "    utm_x, utm_y, utm_zone = plot_utm.loc[uuid][['utm_x', 'utm_y', 'ZONE']]\n",
    "    if utm_zone == '10':\n",
    "        epsg = '6339'\n",
    "    elif utm_zone == '11':\n",
    "        epsg = '6340'\n",
    "    \n",
    "    lon, lat =  pyproj.transform(pyproj.Proj(init='epsg:{}'.format(epsg)),\n",
    "                            pyproj.Proj(init='epsg:4326'),\n",
    "                            utm_x, utm_y)\n",
    "    return lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>utm_x</th>\n",
       "      <th>utm_y</th>\n",
       "      <th>ZONE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uuid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d7c01e3a-38e0-4bc2-a69c-7d5a204e2663</th>\n",
       "      <td>USFS-FREMONT-WINEMA</td>\n",
       "      <td>739655.486497</td>\n",
       "      <td>4.653377e+06</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c16be14e-f913-4516-9c4b-078b3d71371d</th>\n",
       "      <td>USFS-FREMONT-WINEMA</td>\n",
       "      <td>741026.616795</td>\n",
       "      <td>4.653426e+06</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   source          utm_x  \\\n",
       "uuid                                                                       \n",
       "d7c01e3a-38e0-4bc2-a69c-7d5a204e2663  USFS-FREMONT-WINEMA  739655.486497   \n",
       "c16be14e-f913-4516-9c4b-078b3d71371d  USFS-FREMONT-WINEMA  741026.616795   \n",
       "\n",
       "                                             utm_y ZONE  \n",
       "uuid                                                     \n",
       "d7c01e3a-38e0-4bc2-a69c-7d5a204e2663  4.653377e+06   10  \n",
       "c16be14e-f913-4516-9c4b-078b3d71371d  4.653426e+06   10  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_utm.iloc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10N'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_utm_location('d7c01e3a-38e0-4bc2-a69c-7d5a204e2663', is_uuid=True)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classify ground vs non-ground points for the hectare-sized plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def ground_classify(infile):\n",
    "    dirname, basename = os.path.split(infile)\n",
    "    outdir = dirname.replace('interim', 'processed').replace('accepted_plot_clips', 'plot_clips')\n",
    "    outfile = os.path.join(outdir, basename)\n",
    "    \n",
    "    proc = subprocess.run(['wine', '/storage/lidar/LAStools/bin/lasground.exe',\n",
    "                           '-i', infile,\n",
    "                           '-o', outfile],\n",
    "                          stderr=subprocess.PIPE,\n",
    "                          stdout=subprocess.PIPE)\n",
    "    return proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNR_HA = glob.glob('../data/interim/lidar/accepted_plot_clips/dnr_plots/hectare_clips/*.laz')\n",
    "BLM_HA = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/hectare_clips/*.laz')\n",
    "USFS_HA = glob.glob('../data/interim/lidar/accepted_plot_clips/usfs_plots/hectare_clips/*.laz')\n",
    "ALL_HA = DNR_HA + BLM_HA + USFS_HA\n",
    "len(ALL_HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = c.persist([ground_classify(x) for x in ALL_HA])\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clip the hectare-sized classified plot to the appropriate plot size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def clip_smaller_plots(ha_clip):\n",
    "    dirname, basename = os.path.split(ha_clip)\n",
    "    outfile = os.path.join(dirname.replace('hectare', 'plot'), basename)\n",
    "\n",
    "    uuid = os.path.basename(ha_clip).split('_')[0]\n",
    "    \n",
    "    # grab the coordinates of the plot for clipping\n",
    "    x, y = plot_utm.loc[uuid][['utm_x', 'utm_y']]\n",
    "    \n",
    "    source = plot_utm.loc[uuid]['source']\n",
    "    if 'WA-DNR' in source:\n",
    "        # radius of 1/10th acre plot (37.2 ft)\n",
    "        PLOT_RADIUS_M = 11.35  \n",
    "    elif 'USFS' in source:\n",
    "        # radius of 1/4 acre plot (58.9 ft)\n",
    "        PLOT_RADIUS_M = 17.9454 \n",
    "    elif 'BLM' in source:\n",
    "        # radius of 1/8th acre plot (41.6 ft)\n",
    "        PLOT_RADIUS_M = 12.69  \n",
    "    \n",
    "    proc = subprocess.run(['wine', '/storage/lidar/LAStools/bin/las2las.exe',\n",
    "                           '-i', ha_clip,\n",
    "                           '-o', outfile,\n",
    "                           '-keep_circle', str(x), str(y), str(PLOT_RADIUS_M)],\n",
    "                          stderr=subprocess.PIPE,\n",
    "                          stdout=subprocess.PIPE)\n",
    "#     print(outfile, flush=True)\n",
    "    return proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNR_HA = glob.glob('../data/processed/lidar/plot_clips/dnr_plots/hectare_clips/*.laz')\n",
    "BLM_HA = glob.glob('../data/processed/lidar/plot_clips/blm_plots/hectare_clips/*.laz')\n",
    "USFS_HA = glob.glob('../data/processed/lidar/plot_clips/usfs_plots/hectare_clips/*.laz')\n",
    "ALL_HA = DNR_HA + BLM_HA + USFS_HA\n",
    "len(ALL_HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = c.persist([clip_smaller_plots(x) for x in ALL_HA])\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate a hectare-sized plot with points normalized as height above ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def normalize(infile):\n",
    "    dirname, basename = os.path.split(infile)\n",
    "    outdir = dirname.replace('processed', 'interim').replace('plot_clips', 'accepted_plot_clips').replace('hectare_clips', 'hectare_normalized')\n",
    "    outfile = os.path.join(outdir, basename)\n",
    "    \n",
    "    proc = subprocess.run(['wine', '/storage/lidar/LAStools/bin/lasheight.exe',\n",
    "                           '-i', infile,\n",
    "                           '-o', outfile,\n",
    "                           '-replace_z',\n",
    "                           '-drop_below', '-0.1', # below-ground\n",
    "                           '-drop_above', '122'],  # above 400ft\n",
    "                          stderr=subprocess.PIPE,\n",
    "                          stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNR_HA = glob.glob('../data/processed/lidar/plot_clips/dnr_plots/hectare_clips/*.laz')\n",
    "BLM_HA = glob.glob('../data/processed/lidar/plot_clips/blm_plots/hectare_clips/*.laz')\n",
    "USFS_HA = glob.glob('../data/processed/lidar/plot_clips/usfs_plots/hectare_clips/*.laz')\n",
    "ALL_HA = DNR_HA + BLM_HA + USFS_HA\n",
    "len(ALL_HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = c.persist([normalize(x) for x in ALL_HA])\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate a canopy height model from the normalized hectare-sized plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def make_chm(infile):\n",
    "    dirname, basename = os.path.split(infile)\n",
    "    outdir = dirname.replace('hectare_normalized', 'canopymodel')\n",
    "    outfile = os.path.join(outdir, basename.replace('.laz', '.dtm'))\n",
    "    \n",
    "    uuid = basename.split('_')[0]\n",
    "    \n",
    "    # lookup the utm_zone\n",
    "    utm_zone = plot_utm.loc[uuid]['ZONE'] + 'N'\n",
    "    \n",
    "    proc = subprocess.run(['wine', '/storage/lidar/FUSION/canopymodel.exe',\n",
    "                           '/median:3',  # median 3x3 smoothing filter\n",
    "                           '/outlier:-1,122',  # remove outliers below ground or above 400ft\n",
    "                           '/ascii',  # output to ascii as well as dtm\n",
    "                           outfile,  # canopy surface\n",
    "                           '0.5',  # cell size\n",
    "                           'M',  # xyunits\n",
    "                           'M',  # zunits\n",
    "                           '1',  # coordsys, UTM\n",
    "                           utm_zone,  # zone, as in UTM, e.g. '10N'\n",
    "                           '2',  # horizdatum, NAD83\n",
    "                           '2',  # vertdatum, NAVD88\n",
    "                           infile],  # datafiles\n",
    "                         stderr=subprocess.PIPE,\n",
    "                         stdout=subprocess.PIPE)\n",
    "    return proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNR_HA = glob.glob('../data/interim/lidar/accepted_plot_clips/dnr_plots/hectare_normalized/*.laz')\n",
    "BLM_HA = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/hectare_normalized/*.laz')\n",
    "USFS_HA = glob.glob('../data/interim/lidar/accepted_plot_clips/usfs_plots/hectare_normalized/*.laz')\n",
    "ALL_HA = DNR_HA + BLM_HA + USFS_HA\n",
    "len(ALL_HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = c.persist([make_chm(x) for x in ALL_HA])\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.cancel(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate GridSurfaceStats for each hectare-sized plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surface_stats(infile):\n",
    "    dirname, basename = os.path.split(infile)\n",
    "    outdir = dirname.replace('canopymodel', 'gridsurfacestats')\n",
    "    outfile = os.path.join(outdir, basename)\n",
    "    \n",
    "    proc = subprocess.run(['wine', '/storage/lidar/FUSION/GridSurfaceStats.exe',\n",
    "                           '/ascii',\n",
    "                           infile,\n",
    "                           outfile,\n",
    "                           '20'],  # samplefactor, 20*0.5m cells will produce 10*10m grid\n",
    "                         stderr=subprocess.PIPE,\n",
    "                         stdout=subprocess.PIPE)\n",
    "    return proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNR_CHM = glob.glob('../data/interim/lidar/accepted_plot_clips/dnr_plots/canopymodel/*.asc')\n",
    "BLM_CHM = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/canopymodel/*.asc')\n",
    "USFS_CHM = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/canopymodel/*.asc')\n",
    "ALL_CHM = DNR_CHM + BLM_CHM + USFS_CHM\n",
    "len(ALL_CHM)\n",
    "\n",
    "fig, axs = plt.subplots(5,5, figsize=(15,15))\n",
    "imgs = []\n",
    "for i, r in enumerate(DNR_CHM[0:25]):\n",
    "    with rasterio.open(r) as src:\n",
    "        img = src.read(1, masked=True)\n",
    "        imgs.append(img)\n",
    "    axs.ravel()[i].imshow(img, vmin=0, vmax=122)\n",
    "    axs.ravel()[i].set_xticks([])\n",
    "    axs.ravel()[i].set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNR_CHM = glob.glob('../data/interim/lidar/accepted_plot_clips/dnr_plots/canopymodel/*.dtm')\n",
    "BLM_CHM = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/canopymodel/*.dtm')\n",
    "USFS_CHM = glob.glob('../data/interim/lidar/accepted_plot_clips/usfs_plots/canopymodel/*.dtm')\n",
    "ALL_CHM = DNR_CHM + BLM_CHM + USFS_CHM\n",
    "len(ALL_CHM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = c.persist([surface_stats(x) for x in ALL_CHM])\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNR_CHM = glob.glob('../data/interim/lidar/accepted_plot_clips/dnr_plots/gridsurfacestats/*surface_volume.asc')\n",
    "BLM_CHM = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/gridsurfacestats/*surface_volume.asc')\n",
    "USFS_CHM = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/gridsurfacestats/*surface_volume.asc')\n",
    "ALL_CHM = DNR_CHM + BLM_CHM + USFS_CHM\n",
    "len(ALL_CHM)\n",
    "\n",
    "fig, axs = plt.subplots(5,5, figsize=(15,15))\n",
    "imgs = []\n",
    "for i, r in enumerate(USFS_CHM[0:25]):\n",
    "    with rasterio.open(r) as src:\n",
    "        img = src.read(1, masked=True)\n",
    "        imgs.append(img)\n",
    "    axs.ravel()[i].imshow(img)\n",
    "    axs.ravel()[i].set_xticks([])\n",
    "    axs.ravel()[i].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate TopoMetrics for each hectare-sized plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def groundfilter(infile):\n",
    "    dirname, basename = os.path.split(infile)\n",
    "    outdir = dirname.replace('processed', 'interim').replace('plot_clips', 'accepted_plot_clips').replace('hectare_clips', 'bare_ground')\n",
    "    outfile = os.path.join(outdir, basename)\n",
    "    \n",
    "    proc = subprocess.run(['wine', '/storage/lidar/FUSION/groundfilter.exe',\n",
    "                           outfile,\n",
    "                           '0.5',\n",
    "                           infile],\n",
    "                          stderr=subprocess.PIPE,\n",
    "                          stdout=subprocess.PIPE)\n",
    "    return proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5135"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNR_HA = glob.glob('../data/processed/lidar/plot_clips/dnr_plots/hectare_clips/*.laz')\n",
    "BLM_HA = glob.glob('../data/processed/lidar/plot_clips/blm_plots/hectare_clips/*.laz')\n",
    "USFS_HA = glob.glob('../data/processed/lidar/plot_clips/usfs_plots/hectare_clips/*.laz')\n",
    "ALL_HA = DNR_HA + BLM_HA + USFS_HA\n",
    "len(ALL_HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b122ad64d18b4baf80d50013fc234175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = c.persist([groundfilter(f) for f in ALL_HA])\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def tinsurface(infile, utm_zone):\n",
    "    dirname, basename = os.path.split(infile)\n",
    "    outdir = dirname.replace('bare_ground', 'ground_dtm')\n",
    "    outfile = os.path.join(outdir, basename.replace('.laz', '.dtm'))\n",
    "    \n",
    "    proc = subprocess.run(['wine', '/storage/lidar/FUSION/TINSurfaceCreate.exe',\n",
    "                           outfile,\n",
    "                           '0.5',  # cellsize\n",
    "                           'M',  # xy units\n",
    "                           'M',  # z units\n",
    "                           '1',  # coordsys, 1 for UTM\n",
    "                           utm_zone,  # e.g., '10N'\n",
    "                           '2',  # horizdatum, 2 for NAD83\n",
    "                           '2',  # vertdatum, 2 for NAVD88\n",
    "                           infile],\n",
    "                         stderr=subprocess.PIPE,\n",
    "                         stdout=subprocess.PIPE)\n",
    "    return proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5135"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNR_BE = glob.glob('../data/interim/lidar/accepted_plot_clips/dnr_plots/bare_ground/*.laz')\n",
    "BLM_BE = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/bare_ground/*.laz')\n",
    "USFS_BE = glob.glob('../data/interim/lidar/accepted_plot_clips/usfs_plots/bare_ground/*.laz')\n",
    "ALL_BE = DNR_BE + BLM_BE + USFS_BE\n",
    "len(ALL_BE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85dc546d7bc4889aad321fc73de3420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = c.persist([tinsurface(f, get_utm_location(f)[-1]) for f in ALL_BE])\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def topometrics(infile, latitude):\n",
    "    dirname, basename = os.path.split(infile)\n",
    "    outdir = dirname.replace('ground_dtm', 'topometrics')\n",
    "    outfile = os.path.join(outdir, basename.replace('.dtm', '.csv'))\n",
    "    \n",
    "    proc = subprocess.run(['wine', '/storage/lidar/FUSION/TopoMetrics.exe',\n",
    "                           infile,\n",
    "                           '10',  # cellsize\n",
    "                           '20',  # topo point spacing\n",
    "                           str(latitude),\n",
    "                           '1',  # tpi window size\n",
    "                           outfile],\n",
    "                         stderr=subprocess.PIPE,\n",
    "                         stdout=subprocess.PIPE)\n",
    "    return proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5135"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNR_DTM = glob.glob('../data/interim/lidar/accepted_plot_clips/dnr_plots/ground_dtm/*.dtm')\n",
    "BLM_DTM = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/ground_dtm/*.dtm')\n",
    "USFS_DTM = glob.glob('../data/interim/lidar/accepted_plot_clips/usfs_plots/ground_dtm/*.dtm')\n",
    "ALL_DTM = DNR_DTM + BLM_DTM + USFS_DTM\n",
    "len(ALL_DTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d041d8868d4fa9bd553aa0653848f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = c.persist([topometrics(f, get_latitude(f)) for f in ALL_DTM])\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract GridSurfaceStats for each appropriately-sized plot using zonal statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_avg(infile):\n",
    "    dirname, basename = os.path.split(infile)\n",
    "    shp_name = '_'.join(basename.split('_')[0:3])+'.shp'\n",
    "    shp = os.path.join(dirname.replace('gridsurfacestats', 'plot_clips'),\n",
    "                       shp_name)\n",
    "    \n",
    "    zs = zonal_stats(shp, infile, stats=['median'])\n",
    "    return zs[0]['median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNR_GS = glob.glob('../data/interim/lidar/accepted_plot_clips/dnr_plots/gridsurfacestats/*.asc')\n",
    "BLM_GS = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/gridsurfacestats/*.asc')\n",
    "USFS_GS = glob.glob('../data/interim/lidar/accepted_plot_clips/usfs_plots/gridsurfacestats/*.asc')\n",
    "ALL_GS = DNR_GS + BLM_GS + USFS_GS\n",
    "len(ALL_GS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gridstat(f):\n",
    "    stat = '_'.join(os.path.basename(f).split('_')[3:]).split('.asc')[0]\n",
    "    plot_id = '_'.join(os.path.basename(f).split('_')[:3])\n",
    "    return (plot_id, stat, get_plot_avg(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = c.map(get_gridstat, ALL_GS)\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = c.gather(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_grid = pd.pivot(pd.DataFrame(vals, columns=['plot_id', 'gridstat', 'value']), index='plot_id', columns='gridstat', values='value').rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_grid.to_csv('../data/processed/lidar/plot_clips/gridsurfacestats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Extract TopoMetrics for each appropriately-sized plot using zonal statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to execute CSV2Grid to get TopoMetrics out of CSV file and then into an ASCII raster\n",
    "topo_cols_to_grid = {'Elevation (10.00 unit window)':'elevation',\n",
    "                 'Slope (degrees 10.00 unit window)':'slope',\n",
    "                 'Aspect (degrees azimuth 10.00 unit window)':'aspect',\n",
    "                 'Profile curvature * 100 (10.00 unit window)':'profile_curvature',\n",
    "                 'Plan curvature * 100 (10.00 unit window)':'plan_curvature',\n",
    "                 'Solar Radiation Index (10.00 unit window)':'solar_radiation_index',\n",
    "                 'Overall Curvature (10.00 unit window)':'overall_curvature'}\n",
    "\n",
    "@dask.delayed\n",
    "def batch_csv2grid(infile):\n",
    "    \n",
    "    dirname, basename = os.path.split(infile)\n",
    "\n",
    "    with open(infile) as f:\n",
    "        header = f.readline().strip()\n",
    "        cols = header.split(',')\n",
    "        topo_columns = [{'col_num': str(cols.index(col) + 1),\n",
    "                         'col_name': topo_cols_to_grid[col]}\n",
    "                        for col in cols if col in topo_cols_to_grid.keys()]\n",
    "    procs = []\n",
    "    for col in topo_columns:\n",
    "        outfilename = basename.replace('topo_metrics.csv',  \n",
    "                                   col['col_name']+'.asc')\n",
    "        outfile = os.path.join(dirname, outfilename)\n",
    "        proc = subprocess.run(['wine', '/storage/lidar/FUSION/CSV2Grid.exe',\n",
    "                               infile,\n",
    "                               col['col_num'],\n",
    "                               outfile],\n",
    "                              stderr=subprocess.PIPE,\n",
    "                              stdout=subprocess.PIPE)\n",
    "        procs.append(proc)\n",
    "    return procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5135"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNR_CSV = glob.glob('../data/interim/lidar/accepted_plot_clips/dnr_plots/topometrics/*_topo_metrics.csv')\n",
    "BLM_CSV = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/topometrics/*_topo_metrics.csv')\n",
    "USFS_CSV = glob.glob('../data/interim/lidar/accepted_plot_clips/usfs_plots/topometrics/*_topo_metrics.csv')\n",
    "ALL_CSV = DNR_CSV + BLM_CSV + USFS_CSV\n",
    "len(ALL_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73dc81a3e94548f6a907bb81adfe09ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = c.persist([batch_csv2grid(f) for f in ALL_CSV])\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35945"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNR_TOPO = glob.glob('../data/interim/lidar/accepted_plot_clips/dnr_plots/topometrics/*.asc')\n",
    "BLM_TOPO = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/topometrics/*.asc')\n",
    "USFS_TOPO = glob.glob('../data/interim/lidar/accepted_plot_clips/usfs_plots/topometrics/*.asc')\n",
    "ALL_TOPO = DNR_TOPO + BLM_TOPO + USFS_TOPO\n",
    "len(ALL_TOPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topo_avg(infile):\n",
    "    dirname, basename = os.path.split(infile)\n",
    "    shp_name = '_'.join(basename.split('_')[0:3])+'.shp'\n",
    "    shp = os.path.join(dirname.replace('topometrics', 'plot_clips'),\n",
    "                       shp_name)\n",
    "    \n",
    "    zs = zonal_stats(shp, infile, stats=['median'])\n",
    "    return zs[0]['median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topometric(f):\n",
    "    stat = '_'.join(os.path.basename(f).split('_')[3:]).split('.asc')[0]\n",
    "    plot_id = '_'.join(os.path.basename(f).split('_')[:3])\n",
    "    return (plot_id, stat, get_topo_avg(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79724e6f74684d0f812f0a774c42e168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = c.map(get_topometric, ALL_TOPO)\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = c.gather(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_grid = pd.pivot(\n",
    "    pd.DataFrame(vals, \n",
    "                 columns=['plot_id', 'topometric', 'value']), \n",
    "    index='plot_id', \n",
    "    columns='topometric', \n",
    "    values='value').rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_grid.to_csv('../data/processed/lidar/plot_clips/topometrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Clip the normalized hectare plot to appropriate plot size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNR_HA = glob.glob('../data/interim/lidar/accepted_plot_clips/dnr_plots/hectare_normalized/*.laz')\n",
    "BLM_HA = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/hectare_normalized/*.laz')\n",
    "USFS_HA = glob.glob('../data/interim/lidar/accepted_plot_clips/usfs_plots/hectare_normalized/*.laz')\n",
    "ALL_HA = DNR_HA + BLM_HA + USFS_HA\n",
    "len(ALL_HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = c.persist([clip_smaller_plots(x) for x in ALL_HA])\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Execute CloudMetrics for the normalized plot-sized clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def make_cloudmetrics(infile):\n",
    "    dirname, basename = os.path.split(infile)\n",
    "    \n",
    "    # look in ../data/interim/lidar/plot_clips/..._plots/hectare_normalized/\n",
    "    # write to ../data/processed/lidar/plot_clips/..._plots/cloudmetrics\n",
    "    outdir = dirname.replace('plot_normalized', 'cloudmetrics')\n",
    "    outfile = os.path.join(outdir, basename.replace('.laz', '.csv'))\n",
    "    \n",
    "    proc = subprocess.run(['wine', '/storage/lidar/FUSION/cloudmetrics.exe',\n",
    "                           '/above:1.37',\n",
    "                           '/strata:0.15, 1.37, 5.0, 10.0, 20.0, 30.0',\n",
    "                           '/intstrata:0.15, 1.37, 5.0, 10.0, 20.0, 30.0',\n",
    "                           infile,\n",
    "                           outfile],\n",
    "                          stderr=subprocess.PIPE,\n",
    "                          stdout=subprocess.PIPE)\n",
    "                \n",
    "    return proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNR_PLOTS = glob.glob('../data/interim/lidar/accepted_plot_clips/dnr_plots/plot_normalized/*.laz')\n",
    "BLM_PLOTS = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/plot_normalized/*.laz')\n",
    "USFS_PLOTS = glob.glob('../data/interim/lidar/accepted_plot_clips/usfs_plots/plot_normalized/*.laz')\n",
    "ALL_PLOTS = DNR_PLOTS + BLM_PLOTS + USFS_PLOTS\n",
    "len(ALL_PLOTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = c.persist([make_cloudmetrics(x) for x in ALL_PLOTS])\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Consolidate CloudMetrics into a text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNR_CSVS = glob.glob('../data/interim/lidar/accepted_plot_clips/dnr_plots/cloudmetrics/*.csv')\n",
    "BLM_CSVS = glob.glob('../data/interim/lidar/accepted_plot_clips/blm_plots/cloudmetrics/*.csv')\n",
    "USFS_CSVS = glob.glob('../data/interim/lidar/accepted_plot_clips/usfs_plots/cloudmetrics/*.csv')\n",
    "len(DNR_CSVS), len(BLM_CSVS), len(USFS_CSVS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnr_cloudmetrics = pd.concat([pd.read_csv(csv) for csv in DNR_CSVS],\n",
    "                             axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blm_cloudmetrics = pd.concat([pd.read_csv(csv) for csv in BLM_CSVS],\n",
    "                             axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usfs_cloudmetrics = pd.concat([pd.read_csv(csv) for csv in USFS_CSVS],\n",
    "                             axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnr_cloudmetrics.to_csv('../data/processed/lidar/plot_clips/dnr_plots/cloudmetrics.csv',\n",
    "                       index=False)\n",
    "blm_cloudmetrics.to_csv('../data/processed/lidar/plot_clips/blm_plots/cloudmetrics.csv',\n",
    "                       index=False)\n",
    "usfs_cloudmetrics.to_csv('../data/processed/lidar/plot_clips/usfs_plots/cloudmetrics.csv',\n",
    "                        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cloudmetrics = pd.concat([dnr_cloudmetrics, blm_cloudmetrics, usfs_cloudmetrics],\n",
    "                             axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cloudmetrics.to_csv('../data/processed/lidar/plot_clips/cloudmetrics.csv',\n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.cancel(tiles_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.close()\n",
    "# cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyFIRS] *",
   "language": "python",
   "name": "conda-env-pyFIRS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
